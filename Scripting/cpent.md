Generate a Python script to gather information from the target website. The script should prompt for the input URL and perform the following tasks sequentially:
1. Perform website footprinting.
2. Perform website enumeration.  
3. Analyze the HTML source code.
4. Check HTTP/HTML processing by the browser. 
5. Identify server-side technologies.
6. Mirror and crawl the website to identify files, directories, and folders.
7. Identify the sitemap.
8. Extract a common word list.
9. Extract metadata and hidden information.
10. Test whether the Target Website is Protected using a Web Application Firewall (WAF).
11. Test whether the Target Website is Protected using Load Balancers.
12. Perform HTTP service discovery.
13. Perform banner grabbing.  
14. Enumerate web server directories.
15. Test for proxy functionality. 
This script should save the output in 'Information_Gathered.txt' in a structured format. The script should install all the required dependencies and libraries.
